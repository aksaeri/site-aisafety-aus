---
# Leave the homepage title empty to use the site title
title:
date: 2024-05-30
type: landing

sections:
  # Hero Section
  - block: markdown
    content:
      title: |-
        AI is defining our future. Let's get it right.
      text: |-
        The most advanced AI systems are being developed rapidly, creating both unprecedented opportunities and existential risks. Australia has a crucial role to play in ensuring AI benefits humanity.
    design:
      columns: '1'
      background:
        gradient_start: '#2563eb'
        gradient_end: '#1e40af'
        text_color_light: true

  # 1. Learn about AI Safety
  - block: markdown
    id: learn
    content:
      title: Learn about AI Safety
      text: |-
        **AI safety** encompasses work to understand and address risks from increasingly capable AI systems. This includes both current harms and potential catastrophic risks from misaligned AI systems.

        **AI governance** focuses on institutions, policies, and decision-making processes that shape how AI is developed and deployed safely.

        ### Learning Resources

        **[Future of AI Course](https://bluedot.org/courses/future-of-ai)**
        
        BlueDot's accessible 2-hour introduction requiring no technical background. A perfect starting point for understanding AI developments and their implications.

        **[80,000 Hours AI Safety Guide](https://80000hours.org/problem-profiles/artificial-intelligence/)**
        
        Comprehensive problem profile explaining why preventing AI catastrophe is crucial, covering technical safety issues, existential risks, and career paths in the field.

        **[AI Safety Textbook](https://www.aisafetybook.com/)**
        
        "Introduction to AI Safety, Ethics and Society" by Dan Hendrycks. A comprehensive textbook available online for free, also available as audiobook on Spotify.

        **[Geoffrey Hinton Interview](https://www.cbsnews.com/news/geoffrey-hinton-ai-dangers-60-minutes-transcript/)**
        
        Nobel laureate and "Godfather of AI" explains risks in accessible terms, including warnings about loss of human control (60 Minutes, 2024).

        **[International AI Safety Report 2025](https://www.gov.uk/government/publications/international-ai-safety-report-2025)**
        
        Global synthesis from 100 experts across 30 countries on AI capabilities, risks, and safety measures. Comprehensive but lengthy.

        ### Australian Policy Resources

        **[Voluntary AI Safety Standard](https://www.industry.gov.au/publications/voluntary-ai-safety-standard)**
        
        Official Australian government guidance providing 10 practical guardrails for organizations using AI, focusing on transparency, accountability, and risk management.

        **[Mandatory Guardrails Discussion Paper](https://consult.industry.gov.au/ai-mandatory-guardrails)**
        
        Government proposals for mandatory AI safety requirements in high-risk settings, outlining regulatory approaches and implementation options.
        
        **[Australians for AI Safety](https://www.australiansforaisafety.com.au/)**
        
        Expert open letter with policy recommendations for Australian government action on AI risks and safety measures.

        **[Good Ancestors Policy Submission](https://www.goodancestors.org.au/s/Publications-2023-DISR-submission-safe-and-responsible-AI.pdf)**
        
        Detailed policy submission on mandatory guardrails, providing comprehensive recommendations for Australian AI governance frameworks.

    design:
      columns: '2'

  # 2. Australian Organisations and Groups  
  - block: markdown
    id: community
    content:
      title: Australian Organisations and Groups
      text: |-
        Connect with the growing AI safety community across Australia. From research institutes to advocacy groups, there are many ways to get involved.


        **[AI Safety Australia & New Zealand](https://www.facebook.com/groups/1099249420923957/)**
        
        Community for people in Australia or New Zealand interested in preventing existential risk from AI. Organizes regular online events and maintains active discussions on current developments.
        
        [Join the mailing list](https://aisafetysupport.us14.list-manage.com/subscribe?u=d1f02c8a936106ad288cdf2ec&id=2e002b7472) | [Facebook group](https://www.facebook.com/groups/1099249420923957/)

        **[Australians for AI Safety](https://www.australiansforaisafety.com.au/)**
        
        Group of experts publicly advocating for government action on AI risks. They publish open letters and policy recommendations for Australian policymakers and government agencies.

        **[Good Ancestors Project](https://www.goodancestors.org.au/)**
        
        Policy organization developing and advocating for solutions to this century's most challenging problems, including AI governance, biosecurity, and institutional reform.

        **[Gradient Institute](https://www.gradientinstitute.org/)**
        
        Independent nonprofit research institute building safety, ethics, accountability and transparency into AI systems. They develop ethically-aware AI algorithms and provide technical guidance on AI policy development.

        **[CSIRO Responsible AI Engineering](https://research.csiro.au/ss/team/se4ai/responsible-ai-engineering/)**
        
        Australia's national science agency team focusing on responsible AI engineering. They develop frameworks and methodologies for trustworthy AI systems across the entire AI lifecycle.

    design:
      columns: '2'

  # 3. Global Network
  - block: markdown  
    id: global
    content:
      title: Global Network
      text: |-
        Australia is part of a worldwide movement working on AI safety. Connect with leading international organizations driving research and policy development.


        **[Centre for AI Safety](https://www.safe.ai/)**
        
        Leading international organization focused on reducing societal-scale risks from AI. They conduct research, publish policy recommendations, and coordinate global AI safety efforts.

        **[Centre for the Governance of AI](https://www.governance.ai/)**
        
        Research organization providing frameworks for understanding and managing AI risks. They publish reports on public attitudes, policy options, and governance mechanisms for advanced AI systems.

    design:
      columns: '2'

---