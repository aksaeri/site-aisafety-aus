---
# Leave the homepage title empty to use the site title
title:
date: 2024-05-30
type: landing

sections:
  # Hero Section
  - block: hero
    content:
      title: |-
        AI is defining our future. 
        Let's get it right.
      text: |-
        The most advanced AI systems are being developed rapidly, creating both unprecedented opportunities and catastrophic risks. Australia has a crucial role to play in ensuring AI benefits humanity.
    design:
      background:
        image: 
          filename: gilly-tanabose-pdi2gYf9ysM-unsplash.jpg
          filters:
            brightness: 0.3
        text_color_light: true

  # 1. Learn about AI Safety
  - block: markdown
    id: learn
    content:
      title: Learn about AI Safety
      text: |-
        **AI safety** encompasses work to understand and address risks from increasingly capable AI systems. This includes both current harms and potential catastrophic risks from misaligned AI systems.

        **AI governance** focuses on institutions, policies, and decision-making processes that shape how AI is developed and deployed safely.

        ### Learning Resources

        **[Geoffrey Hinton Interview](https://www.youtube.com/watch?v=qrvK_KuIeJk)**
        
        Nobel laureate and "Godfather of AI" Geoffrey Hinton explains AI risks in this 60 Minutes television interview, including warnings about loss of human control (15 mins). Geoffrey Hinton has researched AI for decades, and left Google Brain in 2023 to be able to speak about AI risks more freely.

        **[Yoshua Bengio TED talk](https://www.youtube.com/watch?v=qe9QSCF-d88)**

        Nobel laureate Yoshua Bengio presents the case for taking catastrophic risks from AI seriously in this TED talk (15 mins).

        **[80,000 Hours AI Safety Guide](https://80000hours.org/problem-profiles/artificial-intelligence/)**
        
        Career advice website 80,000 Hours has a guide explaining why preventing AI catastrophe is crucial, introduces technical safety issues, risks, and career paths in the field (~30 mins).

        **[Future of AI Course](https://bluedot.org/courses/future-of-ai)**
        
        Global challenges education non-profit BlueDot Impact has an accessible introduction to the rapid increase in AI capabilities and associated challenges (2 hours). A good starting point to get oriented in AI developments and their implications. BlueDot also offers more in-depth courses in [technical AI Safety](https://bluedot.org/courses/alignment), [AI governance](https://bluedot.org/courses/governance), and [economics of AI](https://bluedot.org/courses/economics-of-tai).

        ### Go deeper

        **[International AI Safety Report 2025](https://www.gov.uk/government/publications/international-ai-safety-report-2025)**
        
        Global synthesis from 100 experts across 30 countries on AI capabilities, risks, and technical safety measures as of early 2025.

        **[AI Safety Textbook](https://www.aisafetybook.com/)**
        
        "Introduction to AI Safety, Ethics and Society" by Dan Hendrycks. A comprehensive free online textbook, also available as audiobook.


        ### Australian Policy Resources

        **[Voluntary AI Safety Standard](https://www.industry.gov.au/publications/voluntary-ai-safety-standard)**
        
        Official Australian government guidance providing 10 practical guardrails for organizations using AI, focusing on transparency, accountability, and risk management.

        **[Mandatory Guardrails Discussion Paper](https://consult.industry.gov.au/ai-mandatory-guardrails)**
        
        Government proposals for mandatory AI safety requirements in high-risk settings, outlining regulatory approaches and implementation options.
        
        **[Good Ancestors Policy Submission](https://www.goodancestors.org.au/s/Publications-2023-DISR-submission-safe-and-responsible-AI.pdf)**
        
        Detailed policy submission on mandatory guardrails, providing comprehensive recommendations for Australian AI governance frameworks.

    design:
      columns: '2'

  # 2. Australian Organisations and Groups  
  - block: markdown
    id: community
    content:
      title: Australian Organisations and Groups
      text: |-
        Connect with the growing AI safety community across Australia. From research institutes to advocacy groups, there are many ways to get involved.


        **[AI Safety Australia & New Zealand](https://aisafetyanz.com.au)**
        
        Community for people in Australia or New Zealand interested in preventing existential risk from AI. Organizes regular online events and maintains active discussions on current developments.
        
        [Join the mailing list](https://aisafetysupport.us14.list-manage.com/subscribe?u=d1f02c8a936106ad288cdf2ec&id=2e002b7472)

        **[Australians for AI Safety](https://www.australiansforaisafety.com.au/)**
        
        Group of experts publicly advocating for government action on AI risks. They publish open letters and policy recommendations for Australian policymakers and government agencies.

        **[Good Ancestors Project](https://www.goodancestors.org.au/)**
        
        Policy organization developing and advocating for solutions to this century's most challenging problems, including AI governance, biosecurity, and institutional reform.

        **[Gradient Institute](https://www.gradientinstitute.org/)**
        
        Independent nonprofit research institute building safety, ethics, accountability and transparency into AI systems. They develop ethically-aware AI algorithms and provide technical guidance on AI policy development.

        **[CSIRO Responsible AI Engineering](https://research.csiro.au/ss/team/se4ai/responsible-ai-engineering/)**
        
        Australia's national science agency team focusing on responsible AI engineering. They develop frameworks and methodologies for trustworthy AI systems across the entire AI lifecycle.

    design:
      columns: '2'

  # # 3. Global Network
  # - block: markdown  
  #   id: global
  #   content:
  #     title: Global Network
  #     text: |-
  #       Australia is part of a worldwide movement working on AI safety. Connect with leading international organizations driving research and policy development.


  #       **[Centre for AI Safety](https://www.safe.ai/)**
        
  #       Leading international organization focused on reducing societal-scale risks from AI. They conduct research, publish policy recommendations, and coordinate global AI safety efforts.

  #       **[Centre for the Governance of AI](https://www.governance.ai/)**
        
  #       Research organization providing frameworks for understanding and managing AI risks. They publish reports on public attitudes, policy options, and governance mechanisms for advanced AI systems.

  #   design:
  #     columns: '2'

---